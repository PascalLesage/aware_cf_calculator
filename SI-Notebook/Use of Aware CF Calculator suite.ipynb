{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample use of the Aware python modules\n",
    "\n",
    "SI provided with the paper \"Quantifying uncertainty for AWARE characterization factors\"\n",
    "\n",
    "**Paper authors:**\n",
    "  - Anne-Marie Boulay (1, 2)\n",
    "  - Pascal Lesage (1) \n",
    "  - Stephan Pfister* (3)\n",
    "  - Ben Amor (2)\n",
    "\n",
    "**Code and notebook author:**\n",
    "  - Pascal Lesage** (1) \n",
    "\n",
    "1: CIRAIG, Polytechnique Montreal, Canada  \n",
    "2: LIRIDE, Sherbrooke University, Canada  \n",
    "3: ETH Zurich, Switzerland\n",
    "\n",
    "\\* Corresponding author for paper (stephan.pfister@ifu.baug.ethz.ch)  \n",
    "\\** Corresponding author for code and notebook (pascal.lesage@polymtl.ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objective-of-this-Notebook\" data-toc-modified-id=\"Objective-of-this-Notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objective of this Notebook</a></span></li><li><span><a href=\"#The-AWARE-model\" data-toc-modified-id=\"The-AWARE-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>The AWARE model</a></span></li><li><span><a href=\"#AwareStatic-module\" data-toc-modified-id=\"AwareStatic-module-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>AwareStatic module</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objective\" data-toc-modified-id=\"Objective-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Objective</a></span></li><li><span><a href=\"#Input-parameters\" data-toc-modified-id=\"Input-parameters-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Input parameters</a></span></li><li><span><a href=\"#Using-AwareStatic\" data-toc-modified-id=\"Using-AwareStatic-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Using AwareStatic</a></span></li></ul></li><li><span><a href=\"#AwareStochastic\" data-toc-modified-id=\"AwareStochastic-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>AwareStochastic</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objective\" data-toc-modified-id=\"Objective-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Objective</a></span></li><li><span><a href=\"#Using-AwareStochastic\" data-toc-modified-id=\"Using-AwareStochastic-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Using AwareStochastic</a></span></li></ul></li><li><span><a href=\"#AwareAnalyser\" data-toc-modified-id=\"AwareAnalyser-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>AwareAnalyser</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objective\" data-toc-modified-id=\"Objective-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Objective</a></span></li><li><span><a href=\"#Sample-use-of-the-AwareAnalyser-methods\" data-toc-modified-id=\"Sample-use-of-the-AwareAnalyser-methods-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Sample use of the AwareAnalyser methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Instantiating-the-AwareAnalyser-object\" data-toc-modified-id=\"Instantiating-the-AwareAnalyser-object-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Instantiating the AwareAnalyser object</a></span></li><li><span><a href=\"#Graphing-results-for-a-watershed-month\" data-toc-modified-id=\"Graphing-results-for-a-watershed-month-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Graphing results for a watershed-month</a></span></li><li><span><a href=\"#Getting-some-stats\" data-toc-modified-id=\"Getting-some-stats-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;</span>Getting some stats</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective of this Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An \"Aware\" module, with three classes (AwareStatic, AwareStochastic, AwareAnalysis) were coded to easily:\n",
    "\n",
    "  - Import and transform in put parameter data to the Aware model  \n",
    "  - Carry out calculations of characterization factors  \n",
    "  - Carry out Monte Carlo simulations to produce arrays of characterization factors  \n",
    "  - Retrieve results  \n",
    "  - Carry out analyses  \n",
    "  \n",
    "The code can be downloaded [here](https://github.com/PascalLesage/aware)  \n",
    "\n",
    "To install and use the package, you must:  \n",
    "  - Download the package [here](XXX)  \n",
    "  - [Install python](https://www.python.org/downloads/). \n",
    "  - Via your command line, navigate to the directory where the package was downloaded  \n",
    "  - Type `python setup aware_cf_calculator`  \n",
    "  \n",
    "To use the package, follow the instructions in this notebook.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The AWARE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWARE is a consensus-based method development to assess water use in LCA. It was developed by the [WULCA UNEP/SETAC working group](http://www.wulca-waterlca.org/index.html). Its characterization factors represent the relative Available WAter REmaining per area in a watershed, after the demand of humans and aquatic ecosystems has been met. It assesses the potential of water deprivation, to either humans or ecosystems, building on the assumption that the less water remaining available per area, the more likely another user will be deprived \n",
    "\n",
    "For information on the actual Aware model, please refer to the [dedicated website](http://www.wulca-waterlca.org/aware.html) and to the paper for which this notebook is a supplementary information.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AwareStatic module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the AwareStatic module is to:  \n",
    "  - import independent parameter values from a formatted Excel file (supplied in the package directory as \"AWARE_base_data.xlsx\")  \n",
    "  - calculate characterization factors for all covered watersheds, both at the monthly level and for three types of annual averages: agricultural use, non-agricultural use, and unspecified use (sometimes refered to as \"unknown use\")  \n",
    "  - output the resulting characterization factors to files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The independent input parameters to the AWARE model are the following:  \n",
    "\n",
    "        Monthly irrigation\n",
    "            Description: irrigation water, per month, per watershed\n",
    "            Unit: m3/month\n",
    "            Location in Excel file: Irrigation\n",
    "            File name once imported: irrigation.pickle\n",
    "            table shape: (11050, 12)\n",
    "\n",
    "        Non-irrigation hwc: electricity, domestic, livestock, manufacturing\n",
    "            Description: non-irrigation uses of water\n",
    "            Unit: m3/year\n",
    "            Location in Excel file: hwc_non_irrigation\n",
    "            File name once imported: electricity.pickle, domestic.pickle,\n",
    "                livestock.pickle, manufacturing.pickle\n",
    "            table shape: 3 x (11050,)\n",
    "\n",
    "        avail_delta\n",
    "            Description: Difference between \"pristine\" natural availability\n",
    "                reported in PastorXNatAvail and natural availability calculated\n",
    "                from \"Actual availability as received from WaterGap - after\n",
    "                human consumption\" (Avail!W:AH) plus HWC.\n",
    "                This should be added to calculated water availability to\n",
    "                get the water availability used for the calculation of EWR\n",
    "            Unit: m3/month\n",
    "            Location in Excel file: avail_delta\n",
    "            File name once imported: avail_delta.pickle\n",
    "            table shape: (11050, 12)\n",
    "\n",
    "        avail_net\n",
    "            Description: Actual availability as received from WaterGap - after human consumption\n",
    "            Unit: m3/month\n",
    "            Location in Excel file: avail_net\n",
    "            File name once imported: avail_net.pickle\n",
    "            table shape: (11050, 12)\n",
    "\n",
    "        pastor\n",
    "            Description: fraction of PRISTINE water availability that should be reserved for environment\n",
    "            Unit: unitless\n",
    "            Location in Excel file: pastor\n",
    "            File name once imported: pastor.pickle\n",
    "            table shape: (11050, 12)\n",
    "\n",
    "        area\n",
    "            Description: area\n",
    "            Unit: m2\n",
    "            Location in Excel file: area\n",
    "            File name once imported: area.pickle\n",
    "            table shape: (11050,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Excel file also contains a \"filters\" sheet which identify watersheds that are excluded from calculations. two such filters exist:  \n",
    "  - Polar filter, which excludes cells from Greenland  \n",
    "  - Pastor filter, which excludes watersheds without data from the Pastor et al. (2014) method (122 cells), representing small coastal cells with no direct overlap  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AwareStatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the AwareStatic module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aware_cf_calculator import AwareStatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine (1) where you want results to be stored and (2) where the Excel file with input parameters is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "dirpath_for_results = Path(r\"C:/mypy/data/AwareSampleUse\")\n",
    "input_data_filepath = Path(r\"../data/AWARE_base_data.xlsx\") \n",
    "# Note: the excel file does not need to be in the same directory as results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an AwareStatic object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already imported\n",
      "Non-CF results already calculated\n",
      "CFs available for ['cfs_0_1_100']\n"
     ]
    }
   ],
   "source": [
    "aware_static = AwareStatic(\n",
    "    base_dir_path=dirpath_for_results,\n",
    "    raw_data_fp=input_data_filepath,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simply extracts the data from the Excel file and applies the Polar and Pastor filters.  \n",
    "\n",
    "To actually calculate the characterization factors, one needs to run the `det_calcs` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_static.det_calcs(\n",
    "    lower_bound=0.1, # default lower bound in CF calculation, see documentation on AWARE\n",
    "    upper_bound=100, # default upper bound in CF calculation, see documentation on AWARE,\n",
    "    dump_excel=True, # save Excel files with results\n",
    "    dump_pickle=True # save pandas dataframes with results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generated Excel files and pandas DataFrames with : \n",
    "  - values for all calculated (intermediate) parameters (e.g. Environmental Water Requirement EWR, Human Water Consumption HWC, etc.).  \n",
    "  - characterization factors (monthly, and three types of annual averages, per watershed)  \n",
    "  \n",
    "These are found in the static_results subdirectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can also be querried directly. Results are stored in the `aware_static.det_results` attribute, which is a dictionary with values = pandas dataframes and keys = parameters or cfs. The valid keys are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HWC',\n",
       " 'avail_before_human_consumption',\n",
       " 'pristine',\n",
       " 'EWR',\n",
       " 'total_AMD',\n",
       " 'AMD_per_m2',\n",
       " 'yearly_AMD_per_m2',\n",
       " 'AMD_world',\n",
       " 'AMD_world_over_AMD_i',\n",
       " 'cfs_monthly',\n",
       " 'cfs_average_unknown',\n",
       " 'cfs_average_agri',\n",
       " 'cfs_average_non_agri']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(aware_static.det_results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax for getting results is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jan</th>\n",
       "      <th>feb</th>\n",
       "      <th>mar</th>\n",
       "      <th>apr</th>\n",
       "      <th>may</th>\n",
       "      <th>jui</th>\n",
       "      <th>jul</th>\n",
       "      <th>aug</th>\n",
       "      <th>sep</th>\n",
       "      <th>oct</th>\n",
       "      <th>nov</th>\n",
       "      <th>dec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS34S_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49896</th>\n",
       "      <td>2.053929e+07</td>\n",
       "      <td>2.792705e+06</td>\n",
       "      <td>4.185863e+06</td>\n",
       "      <td>7.324027e+06</td>\n",
       "      <td>7.934297e+06</td>\n",
       "      <td>1.666263e+07</td>\n",
       "      <td>1.940154e+07</td>\n",
       "      <td>1.189151e+07</td>\n",
       "      <td>7.848574e+06</td>\n",
       "      <td>1.347447e+07</td>\n",
       "      <td>1.871064e+07</td>\n",
       "      <td>2.478544e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "      <td>1.030833e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66449</th>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "      <td>1.312917e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29578</th>\n",
       "      <td>1.246643e+05</td>\n",
       "      <td>1.246643e+05</td>\n",
       "      <td>1.246643e+05</td>\n",
       "      <td>1.246643e+05</td>\n",
       "      <td>1.577733e+05</td>\n",
       "      <td>5.093353e+05</td>\n",
       "      <td>1.278141e+06</td>\n",
       "      <td>1.014414e+06</td>\n",
       "      <td>4.314023e+05</td>\n",
       "      <td>1.396433e+05</td>\n",
       "      <td>1.246643e+05</td>\n",
       "      <td>1.246643e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57778</th>\n",
       "      <td>9.144253e+05</td>\n",
       "      <td>1.036754e+06</td>\n",
       "      <td>1.107232e+06</td>\n",
       "      <td>9.342783e+05</td>\n",
       "      <td>7.876643e+05</td>\n",
       "      <td>6.877193e+05</td>\n",
       "      <td>7.098013e+05</td>\n",
       "      <td>7.865813e+05</td>\n",
       "      <td>8.317763e+05</td>\n",
       "      <td>7.706813e+05</td>\n",
       "      <td>6.572913e+05</td>\n",
       "      <td>7.782973e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    jan           feb           mar           apr  \\\n",
       "BAS34S_ID                                                           \n",
       "49896      2.053929e+07  2.792705e+06  4.185863e+06  7.324027e+06   \n",
       "3013       1.030833e+02  1.030833e+02  1.030833e+02  1.030833e+02   \n",
       "66449      1.312917e+03  1.312917e+03  1.312917e+03  1.312917e+03   \n",
       "29578      1.246643e+05  1.246643e+05  1.246643e+05  1.246643e+05   \n",
       "57778      9.144253e+05  1.036754e+06  1.107232e+06  9.342783e+05   \n",
       "\n",
       "                    may           jui           jul           aug  \\\n",
       "BAS34S_ID                                                           \n",
       "49896      7.934297e+06  1.666263e+07  1.940154e+07  1.189151e+07   \n",
       "3013       1.030833e+02  1.030833e+02  1.030833e+02  1.030833e+02   \n",
       "66449      1.312917e+03  1.312917e+03  1.312917e+03  1.312917e+03   \n",
       "29578      1.577733e+05  5.093353e+05  1.278141e+06  1.014414e+06   \n",
       "57778      7.876643e+05  6.877193e+05  7.098013e+05  7.865813e+05   \n",
       "\n",
       "                    sep           oct           nov           dec  \n",
       "BAS34S_ID                                                          \n",
       "49896      7.848574e+06  1.347447e+07  1.871064e+07  2.478544e+07  \n",
       "3013       1.030833e+02  1.030833e+02  1.030833e+02  1.030833e+02  \n",
       "66449      1.312917e+03  1.312917e+03  1.312917e+03  1.312917e+03  \n",
       "29578      4.314023e+05  1.396433e+05  1.246643e+05  1.246643e+05  \n",
       "57778      8.317763e+05  7.706813e+05  6.572913e+05  7.782973e+05  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HWC results for 5 random watersheds, per month\n",
    "aware_static.det_results['HWC'].sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13414225429829035"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CF value for watershed 59993, month=January\n",
    "aware_static.det_results['cfs_monthly'].loc[59993, 'jan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18919279623174604"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annual average CF (agricultural use) for watershed 41064\n",
    "aware_static.det_results['cfs_average_agri'].loc[59993]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AwareStochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AwareStochastic is used to carry out Monte Carlo simulations to produce sets of random CFs. It first generates random samples for all input random variables, and then uses these to calculate CFs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using AwareStochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aware_cf_calculator import AwareStochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already imported\n",
      "Non-CF results already calculated\n",
      "CFs available for ['cfs_0_1_100']\n",
      "Samples need to be generated.\n",
      "\t200 samples taken for avail_delta_wo_model_uncertainty\n",
      "\t200 samples taken for avail_net_wo_model_uncertainty\n",
      "\t200 samples taken for domestic\n",
      "\t200 samples taken for electricity\n",
      "\t200 samples taken for irrigation\n",
      "\t200 samples taken for livestock\n",
      "\t200 samples taken for manufacturing\n",
      "\t200 samples taken for pastor\n",
      "\t200 samples taken for model_uncertainty\n"
     ]
    }
   ],
   "source": [
    "aware_stochastic = AwareStochastic(\n",
    "    base_dir_path=dirpath_for_results,\n",
    "    sim_name='demo',     # Name of the simulation - many simulations can be carried out with different parameters\n",
    "    consider_certain=[], # Names of parameters to hold static, default is empty list\n",
    "    iterations=200        # Number of iterations for the simulation, small number for this demo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_stochastic.add_model_uncertainty_to_avail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these sampled data, AwareStochastic calculates AMD results (one per iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready to start with  HWC 0 already calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:33\n"
     ]
    }
   ],
   "source": [
    "aware_stochastic.calculate_AMD_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AMD results (and intermediate variables such as HWC) are stored \"one file per iteration, multiple watersheds\". The method `aggregate_results` flips this, saving results \"one file per watershed\" (or watershed-month), with all samples stored in the same order in each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116484 to treat for HWC\n"
     ]
    }
   ],
   "source": [
    "aware_stochastic.aggregate_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the actual calculation of CFs. This can be done for different cut-off values (default is 0.1 and 100 for lower and upper bound on the AMD_world/AMD ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_stochastic.calculate_all_single_month_cfs_stochastic(lower_bound=0.1, upper_bound=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_stochastic.calculate_cfs_average(lower_bound=0.1, upper_bound=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting numpy arrays are stored in the directory `AwareSampleUse/stochastic_results/demo/cfs/0_1_100`  \n",
    "The numpy arrays can be converted to the more well-known `csv` format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_stochastic.convert_dfs_to_csv(lower_bound=0.1, upper_bound=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including model uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach:\n",
    "  - Sample additional uncertainty as independent variable. Use the same approach as `generate_samples`   \n",
    "  - Rename avail_net and avail_delta samples  \n",
    "  - multiply new model uncertainty samples and previous avail_net and avail_delta samples with new factor  \n",
    "  \n",
    "**NOTE** I'll also need to work on AwareAnalyser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, add model_uncertainty to extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_static.imported_raw_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = aware_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile(aware_static.imported_raw_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_name = 'model_uncertainty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(self.imported_raw_data_file, sheet_name=variable_name, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(self.raw_pickles/\"{}.pickle\".format(variable_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.filters_df = pd.read_pickle(self.raw_pickles / \"filters.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.filters_df['total_filter'] = self.filters_df.all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered = pd.read_pickle(self.raw_pickles / \"{}.pickle\".format('model_uncertainty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = unfiltered[self.filters_df['total_filter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.to_pickle(self.filtered_pickles / \"{}.pickle\".format('model_uncertainty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check format of avail_net and avail_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(aware_stochastic.indices_dir/\"avail_delta.pickle\", \"rb\") as f:\n",
    "    avail_delta_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_delta_indices[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avail_delta_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(aware_stochastic.indices_dir/\"avail_net.pickle\", \"rb\") as f:\n",
    "    avail_net_indices = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_net_indices[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avail_net_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(avail_net_indices)-len(avail_delta_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample additionnal uncertainty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(self.filtered_pickles/'model_uncertainty.pickle', 'rb') as f:\n",
    "    model_uncertainty_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uncertainty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uncertainty_df[model_uncertainty_df>12]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uncertainty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df = model_uncertainty_df.stack().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df.rename(columns={'level_1': 'month', 0: 'value'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip\n",
    "stacked_df=stacked_df.rename({'BAS_ID':'BAS34S_ID'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsd2_to_scale = lambda x: np.log(np.sqrt(x))\n",
    "stacked_df['scale']=gsd2_to_scale(stacked_df['value'])\n",
    "stacked_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_arrays_input_dicts = [{'loc': 0, 'scale': stacked_df.loc[i, 'scale'], 'uncertainty_type': 2} for i in stacked_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_arrays_input_dicts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stats_arrays import UncertaintyBase, MCRandomNumberGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_base = UncertaintyBase.from_dicts(*stats_arrays_input_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = MCRandomNumberGenerator(uncertainty_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.iterations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.zeros(shape=[stacked_df.shape[0], self.iterations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(self.iterations):\n",
    "    arr[:, iteration] = next(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_as_arr = np.array([stacked_df['BAS34S_ID'], stacked_df['month']]).T\n",
    "indices_as_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_as_list = [(indices_as_arr[i, 0], indices_as_arr[i, 1]) for i in range(indices_as_arr.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(aware_stochastic.samples_dir / \"{}.npy\".format('model_uncertainty'), arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(aware_stochastic.indices_dir / \"{}.pickle\".format('model_uncertainty'), 'wb') as f:\n",
    "    pickle.dump(indices_as_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiply model_uncertainty with base uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Parameter uncertainty arrays only contain data for parameters that had some uncertainty. HOWEVER, all non-zero values for parameter uncertainty arrays have samples. This means that the model uncertainty would in any case be multiplied by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uncertainty_df = pd.DataFrame(\n",
    "    index=pickle.load(open(aware_stochastic.indices_dir/'model_uncertainty.pickle', 'rb')),\n",
    "    data=np.load(aware_stochastic.samples_dir/'model_uncertainty.npy')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in ['avail_delta']:\n",
    "    param_uncertainty_df = pd.DataFrame(\n",
    "        index=pickle.load(open(aware_stochastic.indices_dir / '{}.pickle'.format(variable), 'rb')),\n",
    "        data=np.load(aware_stochastic.samples_dir / '{}.npy'.format(variable)),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that we have model uncertainty samples for all basin-months with parameter uncertainty\n",
    "assert np.setdiff1d(param_uncertainty_df.index.tolist(), model_uncertainty_df.index.tolist(), assume_unique=True).size == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that all the basin-months for which we do not have parameter uncertainty are indeed for basin-months with 0 values\n",
    "det_df = pd.read_pickle(aware_stochastic.filtered_pickles / \"{}.pickle\".format(variable)).stack()\n",
    "assert det_df.loc[model_uncertainty_df.index.difference(det_df.index)].sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = (avail_net_df * model_uncertainty_df).reindex(avail_net_df.index).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_stochastic.sample_model_uncertainty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AwareAnalyser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AwareAnalyser module has an ad hoc suite of methods that allow an analysis of results.  \n",
    "Some of these methods were used in the analyses in the paper.  \n",
    "It is beyond the scope of this notebook to go into detail in all the types of analyses, but the reader is invited to get to know them and expand upon them.  \n",
    "A sample use of the module is presented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample use of the AwareAnalyser methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating the AwareAnalyser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aware_cf_calculator import AwareAnalyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_analyser = AwareAnalyser(base_dir_path=dirpath_for_results, sim_name=\"demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphing results for a watershed-month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample method: plot histograms for key parameters and cfs for a given watershed/month  \n",
    "Note that the results are for 50 iterations only, which of course is not really sufficient to produce smooth distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_analyser.plot_all_hists_given_basin_and_month(\n",
    "    basin=59993,\n",
    "    month='jan',\n",
    "    lower_bound=0.1,\n",
    "    upper_bound=100,\n",
    "    return_graph=True,\n",
    "    save_graph=False\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get a random list of 10 watersheds\n",
    "import random\n",
    "random_watersheds = random.sample(aware_analyser.basins, 10)\n",
    "\n",
    "# And then let's generate some statistics for the months of January and July for these months\n",
    "cf_stats = aware_analyser.get_full_stats(\n",
    "    result_type='monthly_cf_all', # type aware_analyser.valid_result_types for a list of all result types\n",
    "    basins=random_watersheds,     # use 'all' to generate stats for all watersheds. Be ready to wait a while...\n",
    "    months=['jan', 'jul'],         # use 'all' to generate stats for all months\n",
    "    lower_bound=0.1, upper_bound=100,\n",
    "    aggregate_by_static=False, \n",
    "    augment_with_dispersion=True,\n",
    "    iterations_limiter=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
